{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T17:14:24.527389",
     "start_time": "2017-04-23T10:14:24.033423-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T17:16:04.563895",
     "start_time": "2017-04-23T10:16:04.466319-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subtract by the mean and divide by the standard deviation\n",
    "#normalize data\n",
    "# X_train = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "\n",
    "#unused method to scale from 0 to 1~ish\n",
    "def preproc(unclean_batch_x):\n",
    "    \"\"\"Convert values to range 0-1\"\"\"\n",
    "    temp_batch = unclean_batch_x / unclean_batch_x.max()\n",
    "    return temp_batch\n",
    "#X_train = preproc(X_train)\n",
    "\n",
    "def shuffle(Xtrain, ytrain):\n",
    "    stacked = np.column_stack((Xtrain,ytrain))\n",
    "    np.random.shuffle(stacked)\n",
    "    return stacked[:,:Xtrain.shape[1]], stacked[:,Xtrain.shape[1]]\n",
    "\n",
    "def get_kernel_size(factor):\n",
    "    \"\"\"\n",
    "    Find the kernel size given the desired factor of upsampling.\n",
    "    \"\"\"\n",
    "    return 2 * factor - factor % 2\n",
    "\n",
    "\n",
    "def upsample_filt(size):\n",
    "    \"\"\"\n",
    "    Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "    \"\"\"\n",
    "    factor = (size + 1) // 2\n",
    "    if size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:size, :size]\n",
    "    return (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "# wrapper for applying spatial conv, batchnorm, reLU\n",
    "def conv2d(x, W, b, stride):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    # Batch Norm\n",
    "    x = tf.contrib.layers.batch_norm(x, center=True, scale=True)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def deconv2d(x, W, b, stride):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    # Batch Norm\n",
    "    x = tf.contrib.layers.batch_norm(x, center=True, scale=True)\n",
    "    \n",
    "    # bilinear interpolation upsampling\n",
    "    old_height, old_width = x.get_shape().as_list()[1 : 3]\n",
    "    scale = 2\n",
    "    new_height = old_height * scale\n",
    "    new_width = old_width * scale\n",
    "    return tf.image.resize_images(x, [new_height, new_width], method=tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "ENCODER = 'encoder'\n",
    "MID = 'mid'\n",
    "DECODER = 'decoder'\n",
    "\n",
    "def get_weight_name(stage, layer_num):\n",
    "    return 'w_' + stage + '_' + str(layer_num)\n",
    "    \n",
    "def get_bias_name(stage, layer_num):\n",
    "    return 'b_' + stage + '_' + str(layer_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T17:16:04.833661",
     "start_time": "2017-04-23T10:16:04.699564-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IntrinsicNetwork(object):\n",
    "    def __init__(self, input_dimensions, encoder_dimensions, mid_dimensions, decoder_dimensions):\n",
    "        self.params = {}\n",
    "        # in the paper each input sample is 256x256x3\n",
    "        self.input = tf.placeholder(tf.float32, shape=[None,] + list(input_dimensions))\n",
    "        \n",
    "        encoder_layers = self.get_encoder_layers(self.input, encoder_dimensions)\n",
    "        mid_output = self.get_mid_output(encoder_layers[-1], mid_dimensions)\n",
    "        self.output = self.get_decoder_output(mid_output, encoder_layers, decoder_dimensions)\n",
    "        \n",
    "    def get_encoder_layers(self, input, dimensions):\n",
    "        prev = input\n",
    "        encoder_layers = []\n",
    "        # encoder layers 0 to 5\n",
    "        for layer_num in range(6):\n",
    "            # initilize weights\n",
    "            dims = dimensions[get_weight_name(ENCODER, layer_num)]\n",
    "            input_depth, output_depth, stride, filter_size = \\\n",
    "                (dims[x] for x in ['input_depth', 'output_depth', 'stride', 'filter_size'])\n",
    "            W = tf.Variable(tf.random_normal([filter_size, filter_size, input_depth, output_depth]))\n",
    "            b = tf.Variable(tf.random_normal([output_depth]))\n",
    "            self.params[get_weight_name(ENCODER, layer_num)] = W\n",
    "            self.params[get_bias_name(ENCODER, layer_num)] = b\n",
    "            prev = conv2d(prev, W, b, stride)\n",
    "            encoder_layers.append(prev)\n",
    "        return encoder_layers\n",
    "    \n",
    "    def get_mid_output(self, encoder_output, dimensions):\n",
    "        prev = encoder_output\n",
    "        for layer_num in range(4):\n",
    "            dims = dimensions[get_weight_name(MID, layer_num)]\n",
    "            input_depth, output_depth, stride, filter_size = \\\n",
    "                (dims[x] for x in ['input_depth', 'output_depth', 'stride', 'filter_size'])\n",
    "            W = tf.Variable(tf.random_normal([filter_size, filter_size, input_depth, output_depth]))\n",
    "            b = tf.Variable(tf.random_normal([output_depth]))\n",
    "            self.params[get_weight_name(MID, layer_num)] = W\n",
    "            self.params[get_bias_name(MID, layer_num)] = b\n",
    "            prev = conv2d(prev, W, b, stride)\n",
    "        return prev\n",
    "    \n",
    "    def get_decoder_output(self, mid_output, encoder_layers, dimensions):\n",
    "        prev = mid_output\n",
    "        for layer_num in range(7):\n",
    "            dims = dimensions[get_weight_name(DECODER, layer_num)]\n",
    "            input_depth, output_depth, stride, filter_size = \\\n",
    "                (dims[x] for x in ['input_depth', 'output_depth', 'stride', 'filter_size'])\n",
    "            W = tf.Variable(tf.random_normal([filter_size, filter_size, input_depth, output_depth]))\n",
    "            b = tf.Variable(tf.random_normal([output_depth]))\n",
    "            self.params[get_weight_name(DECODER, layer_num)] = W\n",
    "            self.params[get_bias_name(DECODER, layer_num)] = b\n",
    "            \n",
    "            if layer_num < 6: # concatenate with encoder layer for layers 0 to 5\n",
    "                encoder_layer_input = encoder_layers[5 - layer_num]\n",
    "                prev = tf.concat([prev, encoder_layer_input], axis=3)\n",
    "            if layer_num < 5: # perform deconv on layers 0 to 4\n",
    "                prev = deconv2d(prev, W, b, stride)\n",
    "            else: # conv on layers 5 and 6\n",
    "                prev = conv2d(prev, W, b, stride)\n",
    "        return prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T17:16:05.410502",
     "start_time": "2017-04-23T10:16:05.360464-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "# more parameters\n",
    "FILTER_SIZE = 3\n",
    "INPUT_DEPTH = 3\n",
    "\n",
    "# output depths of the layers\n",
    "ENCODER_DEPTHS = [16, 32, 64, 128, 256, 256]\n",
    "MID_DEPTH = encoder_depths[-1]\n",
    "DECODER_DEPTHS = [256, 128, 64, 32, 16, 16, 3]\n",
    "\n",
    "# defines the sizes for each of the conv / deconv layers\n",
    "encoder_dimensions = {}\n",
    "prev_depth = INPUT_DEPTH\n",
    "for i, output_depth in enumerate(ENCODER_DEPTHS):\n",
    "    weight_name = get_weight_name(ENCODER, i)\n",
    "    stride = 1 if i == 0 else 2 # stride 1 for the first conv layer only\n",
    "    encoder_dimensions[weight_name] = {\n",
    "        'input_depth' : prev_depth,\n",
    "        'output_depth' : output_depth,\n",
    "        'stride' : stride,\n",
    "        'filter_size' : FILTER_SIZE\n",
    "    }\n",
    "    prev_depth = output_depth\n",
    "\n",
    "mid_dimensions = {}\n",
    "for i in range(4):\n",
    "    weight_name = get_weight_name(MID, i)\n",
    "    mid_dimensions[weight_name] = {\n",
    "        'input_depth' : MID_DEPTH,\n",
    "        'output_depth' : MID_DEPTH,\n",
    "        'stride' : 1,\n",
    "        'filter_size' : FILTER_SIZE\n",
    "    }\n",
    "\n",
    "decoder_dimensions = {}\n",
    "prev_depth = mid_depth\n",
    "for i, output_depth in enumerate(DECODER_DEPTHS):\n",
    "    # the ith deconv layer's input is the concatenation of the previous output and the output of (5-i)th encoder conv layer\n",
    "    # so the depth is the sum of the depths\n",
    "    # the last two layers in this loop (5th and 6th layer) are conv layers, not deconv\n",
    "    if i < 6:\n",
    "        prev_encoder_depth = encoder_depths[5 - i]\n",
    "        input_depth = prev_depth + prev_encoder_depth\n",
    "    else: # 6th layer doesn't have concatenation\n",
    "        input_depth = prev_depth\n",
    "    weight_name = get_weight_name(DECODER, i)\n",
    "    decoder_dimensions[weight_name] = {\n",
    "        'input_depth' : input_depth,\n",
    "        'output_depth' : output_depth,\n",
    "        'stride' : 1,\n",
    "        'filter_size' : FILTER_SIZE\n",
    "    }\n",
    "    prev_depth = output_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T17:16:08.706617",
     "start_time": "2017-04-23T10:16:06.260292-07:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.IntrinsicNetwork at 0x229c04a1588>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IntrinsicNetwork((256, 256, INPUT_DEPTH), encoder_dimensions, mid_dimensions, decoder_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T18:07:48.050464",
     "start_time": "2017-04-23T11:07:16.344692-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "params = []\n",
    "end_re = re.compile(r'^\\[torch.CudaTensor of size (\\w+)\\]')\n",
    "index_re = re.compile(r'^\\((\\d+),(\\d+)')\n",
    "with open('shapenet_intrinsics/train/model_weights.txt') as f:\n",
    "    current = []\n",
    "    linenum = 1\n",
    "    for line in f:\n",
    "        end = end_re.match(line)\n",
    "        if end:\n",
    "            end_dims = tuple(map(int, end.group(1).split('x')))\n",
    "            if len(end_dims) == 1:\n",
    "                if current[0].startswith('0.01 *'):\n",
    "                    current = current[1:]\n",
    "                array = np.array(tuple(map(float, current)))\n",
    "                assert(len(array) == end_dims[0])\n",
    "            else:\n",
    "                array = np.zeros(end_dims)\n",
    "                i = 0\n",
    "                while i < len(current):\n",
    "                    match = index_re.match(current[i])\n",
    "                    first_index = int(match.group(1)) - 1\n",
    "                    second_index = int(match.group(2)) - 1\n",
    "                    for j in range(3):\n",
    "                        array[first_index][second_index][j] = np.array(tuple(map(float, current[i + 1 + j].lstrip().split())))\n",
    "                    i += 5\n",
    "            params.append(array)\n",
    "            current = []\n",
    "            continue\n",
    "        current.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch size of one = stochastic gradient descent, mini-batch gradient descent\n",
    "# should use 10 at once\n",
    "# mini batch neural nets tensorflow\n",
    "# fc, relu, maybe a few repetitions, softmax\n",
    "\n",
    "M = 70 #M is the input size factor\n",
    "\n",
    "input_size = 32*M # 28 x 28\n",
    "output_size = 32*M\n",
    "\n",
    "# dropout = 0.8 # probability of keeping that data point\n",
    "# dropout2 = 0.9\n",
    "\n",
    "# learning_rate = 0.5\n",
    "\n",
    "# data placeholders\n",
    "\n",
    "# input data\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "# correct answers\n",
    "y = tf.placeholder(tf.float32, [None, output_size])\n",
    "# dropout variable\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "keep_prob2 = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# more parameters\n",
    "batch_size = 30\n",
    "epochs = 5\n",
    "\n",
    "display_step = 1\n",
    "\n",
    "n_samples = x_training.shape[0]\n",
    "#rounds_number = data_size/ batch_size\n",
    "\n",
    "mean_losses = []\n",
    "mean_accs = []\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Keep training until reach max iterations\n",
    "    for epoch in range(epochs):\n",
    "        print(\"running epoch: \", epoch)\n",
    "        total_iter = n_samples // batch_size #total_iter\n",
    "        total_loss = 0\n",
    "#         indeces = np.random.permutations(np.arange(len(n_samples))\n",
    "        \n",
    "        for i in range(total_iter):\n",
    "#             x = X[i * batch_size : (i + 1) * batch_size]\n",
    "            start = i * batch_size\n",
    "            end = (i + 1) * batch_size\n",
    "            batch_x, batch_y = x_training[start:end], labels_training[start:end]\n",
    "            \n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout, keep_prob2: dropout2})\n",
    "            \n",
    "            # Calculate batch loss and accuracy \n",
    "#             loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1., keep_prob2: 1.})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y, keep_prob: 1., keep_prob2: 1.})\n",
    "#             loss = self.fit_batch(x)\n",
    "            total_loss += loss\n",
    "#             total_acc += acc\n",
    "\n",
    "            if i%100 == 0:\n",
    "                print(\"epoch: \",epoch,\", iteration: \",i,\", loss: \",loss,\" total loss: \",total_loss)\n",
    "    \n",
    "    \n",
    "        mean_loss = total_loss / total_iter\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "#         mean_acc = total_acc / total_iter\n",
    "#         mean_accs.append(mean_acc)\n",
    "        \n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print('epoch %s: loss=%.4f' % (epoch + 1, mean_loss))\n",
    "            \n",
    "    \n",
    "    # Calculate accuracy for test images\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: x_valid, y: labels_valid, keep_prob: 1., keep_prob2: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unused implementation of fully connected layer\n",
    "\n",
    "# Fully connected layer\n",
    "# Reshape conv2 output to fit fully connected layer input\n",
    "fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "print(\"fc1 shape\", fc1.shape)\n",
    "fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "fc1 = tf.nn.relu(fc1)\n",
    "print(\"fc1 shape after weights and biases\", fc1.shape)\n",
    "# Apply Dropout\n",
    "fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "# Output, class prediction (dense layer)\n",
    "fc2 = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "print(\"fc2 shape after weights and biases\", fc2.shape)\n",
    "#     fc2 = tf.nn.dropout(fc2, dropout2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
